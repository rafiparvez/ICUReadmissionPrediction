{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import csv\n",
    "import re\n",
    "from sklearn.model_selection import KFold,train_test_split,StratifiedKFold\n",
    "\n",
    "mimic3_path=\"/home/rafiparvez1706/mimic\"\n",
    "output_path =\"../data/root\"\n",
    "variable_map_file='../resources/itemid_to_variable_map.csv'\n",
    "icu_stays_root_path=output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4d8cf1d1bb09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read all stays data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/clean_readm_details.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# read all stays data\n",
    "stays = pd.read_csv('../data/clean_readm_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.778741865509762"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(stays.IsReadmitted==1)*100/len(stays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>last_wardid</th>\n",
       "      <th>first_careunit</th>\n",
       "      <th>last_careunit</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>insurance</th>\n",
       "      <th>IsReadmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>12</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>76.526788</td>\n",
       "      <td>M</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>294638</td>\n",
       "      <td>52</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>47.845044</td>\n",
       "      <td>F</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>Private</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>107064</td>\n",
       "      <td>228232</td>\n",
       "      <td>33</td>\n",
       "      <td>SICU</td>\n",
       "      <td>SICU</td>\n",
       "      <td>65.940670</td>\n",
       "      <td>F</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>150750</td>\n",
       "      <td>220597</td>\n",
       "      <td>15</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>41.790226</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>194540</td>\n",
       "      <td>229441</td>\n",
       "      <td>57</td>\n",
       "      <td>SICU</td>\n",
       "      <td>SICU</td>\n",
       "      <td>50.148292</td>\n",
       "      <td>F</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>Private</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  hadm_id  icustay_id  last_wardid first_careunit last_careunit  \\\n",
       "0           3   145834      211552           12           MICU          MICU   \n",
       "1           4   185777      294638           52           MICU          MICU   \n",
       "2           6   107064      228232           33           SICU          SICU   \n",
       "3           9   150750      220597           15           MICU          MICU   \n",
       "4          11   194540      229441           57           SICU          SICU   \n",
       "\n",
       "         age gender marital_status insurance  IsReadmitted  \n",
       "0  76.526788      M        MARRIED  Medicare             0  \n",
       "1  47.845044      F         SINGLE   Private             0  \n",
       "2  65.940670      F        MARRIED  Medicare             0  \n",
       "3  41.790226      M            NaN  Medicaid             0  \n",
       "4  50.148292      F        MARRIED   Private             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def break_up_stays_by_icustayids(stays, output_path, verbose=1):\n",
    "    icustay_ids = stays.icustay_id.unique()\n",
    "    for i, icustay_id in enumerate(icustay_ids):\n",
    "        if verbose:\n",
    "            sys.stdout.write('\\ricustay_id {0} of {1}...'.format(i+1, icustay_ids.shape[0]))\n",
    "        dn = os.path.join(output_path, str(icustay_id))\n",
    "        if os.path.exists(dn):\n",
    "            shutil.rmtree(dn)\n",
    "        os.makedirs(dn)        \n",
    "        stays.loc[stays.icustay_id == icustay_id].to_csv(os.path.join(dn, 'stays.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbreak_up_stays_by_icustayids(stays,output_path)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "break_up_stays_by_icustayids(stays,output_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_events_table_by_row(mimic3_path, table):\n",
    "    nb_rows = { 'chartevents': 263201376, 'labevents': 27872576, 'outputevents': 4349340 }\n",
    "    reader = csv.DictReader(open(os.path.join(mimic3_path, table.upper() + '.csv'), 'r'))\n",
    "    for i,row in enumerate(reader):\n",
    "        if 'ICUSTAY_ID' not in row:\n",
    "            row['ICUSTAY_ID'] = ''\n",
    "        yield row, i, nb_rows[table.lower()]\n",
    "        \n",
    "def read_events_table_and_break_up_by_icu_stay(mimic3_path, table, output_path,items_to_keep=None, icu_stay_ids_to_keep=None, verbose=1):\n",
    "    obs_header = [ 'SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'CHARTTIME', 'ITEMID', 'VALUE', 'VALUEUOM' ]\n",
    "    if items_to_keep is not None:\n",
    "        items_to_keep = set([ str(s) for s in items_to_keep ])\n",
    "    if icu_stay_ids_to_keep is not None:\n",
    "        icu_stay_ids_to_keep = set([ str(i) for i in icu_stay_ids_to_keep ])\n",
    "\n",
    "    class DataStats(object):\n",
    "        def __init__(self):\n",
    "            self.curr_icu_stay_id = ''\n",
    "            self.last_write_no = 0\n",
    "            self.last_write_nb_rows = 0\n",
    "            self.last_write_icu_stay_id = ''\n",
    "            self.curr_obs = []\n",
    "\n",
    "    data_stats = DataStats()\n",
    "\n",
    "    def write_current_observations():\n",
    "        data_stats.last_write_no += 1\n",
    "        data_stats.last_write_nb_rows = len(data_stats.curr_obs)\n",
    "        data_stats.last_write_icu_stay_id = data_stats.curr_icu_stay_id\n",
    "        dn = os.path.join(output_path, str(data_stats.curr_icu_stay_id))\n",
    "        try:\n",
    "            os.makedirs(dn)\n",
    "        except:\n",
    "            pass\n",
    "        fn = os.path.join(dn, 'events.csv')\n",
    "        if not os.path.exists(fn) or not os.path.isfile(fn):\n",
    "            f = open(fn, 'w')\n",
    "            f.write(','.join(obs_header) + '\\n')\n",
    "            f.close()\n",
    "        w = csv.DictWriter(open(fn, 'a'), fieldnames=obs_header, quoting=csv.QUOTE_MINIMAL)\n",
    "        w.writerows(data_stats.curr_obs)\n",
    "        data_stats.curr_obs = []\n",
    "    \n",
    "    for row, row_no, nb_rows in read_events_table_by_row(mimic3_path, table):\n",
    "        if verbose and (row_no % 100000 == 0):\n",
    "            if data_stats.last_write_no != '':\n",
    "                sys.stdout.write('\\rprocessing {0}: ROW {1} of {2}...last write '\n",
    "                                 '({3}) {4} rows for icu_stay {5}'.format(table, row_no, nb_rows,\n",
    "                                                                         data_stats.last_write_no,\n",
    "                                                                         data_stats.last_write_nb_rows,\n",
    "                                                                         data_stats.last_write_icu_stay_id))\n",
    "            else:\n",
    "                sys.stdout.write('\\rprocessing {0}: ROW {1} of {2}...'.format(table, row_no, nb_rows))\n",
    "        \n",
    "        if (icu_stay_ids_to_keep is not None and row['ICUSTAY_ID'] not in icu_stay_ids_to_keep):\n",
    "            continue\n",
    "        if (items_to_keep is not None and row['ITEMID'] not in items_to_keep):\n",
    "            continue\n",
    "        \n",
    "        row_out = { 'SUBJECT_ID': row['SUBJECT_ID'],\n",
    "                    'HADM_ID': row['HADM_ID'],\n",
    "                    'ICUSTAY_ID': '' if 'ICUSTAY_ID' not in row else row['ICUSTAY_ID'],\n",
    "                    'CHARTTIME': row['CHARTTIME'],\n",
    "                    'ITEMID': row['ITEMID'],\n",
    "                    'VALUE': row['VALUE'],\n",
    "                    'VALUEUOM': row['VALUEUOM'] }\n",
    "        if data_stats.curr_icu_stay_id != '' and data_stats.curr_icu_stay_id != row['ICUSTAY_ID']:\n",
    "            write_current_observations()\n",
    "        data_stats.curr_obs.append(row_out)\n",
    "        data_stats.curr_icu_stay_id = row['ICUSTAY_ID']\n",
    "        \n",
    "    if data_stats.curr_icu_stay_id != '':\n",
    "        write_current_observations()\n",
    "\n",
    "    if verbose and (row_no % 100000 == 0):\n",
    "        sys.stdout.write('\\rprocessing {0}: ROW {1} of {2}...last write '\n",
    "                         '({3}) {4} rows for icu_stay {5}...DONE!\\n'.format(table, row_no, nb_rows,\n",
    "                                                                 data_stats.last_write_no,\n",
    "                                                                 data_stats.last_write_nb_rows,\n",
    "                                                                 data_stats.last_write_icu_stay_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nitems_to_keep=None\\nicu_stay_ids=None\\n\\nfor table in ['CHARTEVENTS', 'LABEVENTS', 'OUTPUTEVENTS']: \\n    read_events_table_and_break_up_by_icu_stay(mimic3_path, table, output_path,\\n                                               items_to_keep=items_to_keep,icu_stay_ids_to_keep=icu_stay_ids, verbose=1)\\n                                               \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add events details to each icu stay id\n",
    "'''\n",
    "items_to_keep=None\n",
    "icu_stay_ids=None\n",
    "\n",
    "for table in ['CHARTEVENTS', 'LABEVENTS', 'OUTPUTEVENTS']: \n",
    "    read_events_table_and_break_up_by_icu_stay(mimic3_path, table, output_path,\n",
    "                                               items_to_keep=items_to_keep,icu_stay_ids_to_keep=icu_stay_ids, verbose=1)\n",
    "                                               '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#events_sample = pd.read_csv('../data/root/226799/events.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now creating time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_itemid_to_variable_map(fn, variable_column='LEVEL2'):\n",
    "    var_map = pd.read_csv(fn, index_col=None).fillna('').astype(str)\n",
    "\n",
    "    var_map.COUNT = var_map.COUNT.astype(int)\n",
    "\n",
    "    var_map = var_map.loc[(var_map[variable_column] != '') & (var_map.COUNT>0)]\n",
    "    var_map = var_map.loc[(var_map.STATUS == 'ready')]\n",
    "    var_map.ITEMID = var_map.ITEMID.astype(int)\n",
    "    var_map = var_map[[variable_column, 'ITEMID', 'MIMIC LABEL']].set_index('ITEMID')\n",
    "    return var_map.rename({variable_column: 'VARIABLE', 'MIMIC LABEL': 'MIMIC_LABEL'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Capillary refill rate', 'Diastolic blood pressure',\n",
       "       'Fraction inspired oxygen', 'Glascow coma scale eye opening',\n",
       "       'Glascow coma scale motor response', 'Glascow coma scale total',\n",
       "       'Glascow coma scale verbal response', 'Glucose', 'Heart Rate',\n",
       "       'Height', 'Mean blood pressure', 'Oxygen saturation', 'pH',\n",
       "       'Respiratory rate', 'Systolic blood pressure', 'Temperature',\n",
       "       'Weight'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_map = read_itemid_to_variable_map(variable_map_file)\n",
    "variables = var_map.VARIABLE.unique()\n",
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#db Connection String\n",
    "# Create a database connection\n",
    "user = 'postgres'\n",
    "host = 'xx.xxx.xx.xxx'\n",
    "dbname = 'mimic'\n",
    "schema = 'mimiciii'\n",
    "password ='xxxx'\n",
    "port = '5432'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_map = { 'F': 1, 'M': 2, 'OTHER': 3, '': 0 }\n",
    "def transform_gender(gender_series):\n",
    "    global g_map\n",
    "    return gender_series.fillna('').apply(lambda s: g_map[s] if s in g_map else g_map['OTHER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SBP: some are strings of type SBP/DBP\n",
    "def clean_sbp(df):\n",
    "    v = df.VALUE.astype(str)\n",
    "    idx = v.apply(lambda s: '/' in s)\n",
    "    v.loc[idx] = v.loc[idx].apply(lambda s: re.match('^(\\d+)/(\\d+)$', s).group(1))\n",
    "    return v.astype(float)\n",
    "\n",
    "def clean_dbp(df):\n",
    "    v = df.VALUE.astype(str)\n",
    "    idx = v.apply(lambda s: '/' in s)\n",
    "    v.loc[idx] = v.loc[idx].apply(lambda s: re.match('^(\\d+)/(\\d+)$', s).group(2))\n",
    "    return v.astype(float)\n",
    "\n",
    "# CRR: strings with brisk, <3 normal, delayed, or >3 abnormal\n",
    "def clean_crr(df):\n",
    "    v = Series(np.zeros(df.shape[0]), index=df.index)\n",
    "    v[:] = np.nan\n",
    "    \n",
    "    # when df.VALUE is empty, dtype can be float and comparision with string\n",
    "    # raises an exception, to fix this we change dtype to str\n",
    "    df.VALUE = df.VALUE.astype(str)\n",
    "    \n",
    "    v.loc[(df.VALUE == 'Normal <3 secs') | (df.VALUE == 'Brisk')] = 0\n",
    "    v.loc[(df.VALUE == 'Abnormal >3 secs') | (df.VALUE == 'Delayed')] = 1\n",
    "    return v\n",
    "\n",
    "# FIO2: many 0s, some 0<x<0.2 or 1<x<20\n",
    "def clean_fio2(df):\n",
    "    v = df.VALUE.astype(float)\n",
    "    idx = df.VALUEUOM.fillna('').apply(lambda s: 'torr' not in s.lower()) & (v>1.0)\n",
    "    v.loc[idx] = v.loc[idx] / 100.\n",
    "    return v\n",
    "\n",
    "# GLUCOSE, PH: sometimes have ERROR as value\n",
    "def clean_lab(df):\n",
    "    v = df.VALUE\n",
    "    idx = v.apply(lambda s: type(s) is str and not re.match('^(\\d+(\\.\\d*)?|\\.\\d+)$', s))\n",
    "    v.loc[idx] = np.nan\n",
    "    return v.astype(float)\n",
    "\n",
    "# O2SAT: small number of 0<x<=1 that should be mapped to 0-100 scale\n",
    "def clean_o2sat(df):\n",
    "    # change \"ERROR\" to NaN\n",
    "    v = df.VALUE\n",
    "    idx = v.apply(lambda s: type(s) is str and not re.match('^(\\d+(\\.\\d*)?|\\.\\d+)$', s))\n",
    "    v.loc[idx] = np.nan\n",
    "    \n",
    "    v = v.astype(float)\n",
    "    idx = (v<=1)\n",
    "    v.loc[idx] = v.loc[idx] * 100.\n",
    "    return v\n",
    "\n",
    "# Temperature: map Farenheit to Celsius, some ambiguous 50<x<80\n",
    "def clean_temperature(df):\n",
    "    v = df.VALUE.astype(float)\n",
    "    idx = df.VALUEUOM.fillna('').apply(lambda s: 'F' in s.lower()) | df.MIMIC_LABEL.apply(lambda s: 'F' in s.lower()) | (v >= 79)\n",
    "    v.loc[idx] = (v.loc[idx] - 32) * 5. / 9\n",
    "    return v\n",
    "\n",
    "# Weight: some really light/heavy adults: <50 lb, >450 lb, ambiguous oz/lb\n",
    "# Children are tough for height, weight\n",
    "def clean_weight(df):\n",
    "    v = df.VALUE.astype(float)\n",
    "    # ounces\n",
    "    idx = df.VALUEUOM.fillna('').apply(lambda s: 'oz' in s.lower()) | df.MIMIC_LABEL.apply(lambda s: 'oz' in s.lower())\n",
    "    v.loc[idx] = v.loc[idx] / 16.\n",
    "    # pounds\n",
    "    idx = idx | df.VALUEUOM.fillna('').apply(lambda s: 'lb' in s.lower()) | df.MIMIC_LABEL.apply(lambda s: 'lb' in s.lower())\n",
    "    v.loc[idx] = v.loc[idx] * 0.453592\n",
    "    return v\n",
    "\n",
    "# Height: some really short/tall adults: <2 ft, >7 ft)\n",
    "# Children are tough for height, weight\n",
    "def clean_height(df):\n",
    "    v = df.VALUE.astype(float)\n",
    "    idx = df.VALUEUOM.fillna('').apply(lambda s: 'in' in s.lower()) | df.MIMIC_LABEL.apply(lambda s: 'in' in s.lower())\n",
    "    v.loc[idx] = np.round(v.loc[idx] * 2.54)\n",
    "    return v\n",
    "\n",
    "# ETCO2: haven't found yet\n",
    "# Urine output: ambiguous units (raw ccs, ccs/kg/hr, 24-hr, etc.)\n",
    "# Tidal volume: tried to substitute for ETCO2 but units are ambiguous\n",
    "# Glascow coma scale eye opening\n",
    "# Glascow coma scale motor response\n",
    "# Glascow coma scale total\n",
    "# Glascow coma scale verbal response\n",
    "# Heart Rate\n",
    "# Respiratory rate\n",
    "# Mean blood pressure\n",
    "clean_fns = {\n",
    "    'Capillary refill rate': clean_crr,\n",
    "    'Diastolic blood pressure': clean_dbp,\n",
    "    'Systolic blood pressure': clean_sbp,\n",
    "    'Fraction inspired oxygen': clean_fio2,\n",
    "    'Oxygen saturation': clean_o2sat,\n",
    "    'Glucose': clean_lab,\n",
    "    'pH': clean_lab,\n",
    "    'Temperature': clean_temperature,\n",
    "    'Weight': clean_weight,\n",
    "    'Height': clean_height\n",
    "}\n",
    "def clean_events(events):\n",
    "    global cleaning_fns\n",
    "    for var_name, clean_fn in clean_fns.items():\n",
    "        idx = (events.VARIABLE == var_name)\n",
    "        try:\n",
    "            events.VALUE.loc[idx] = clean_fn(events.loc[idx])\n",
    "        except Exception as e:\n",
    "            print(\"Exception in clean_events:\", clean_fn.__name__, e)\n",
    "            print(\"number of rows:\", np.sum(idx))\n",
    "            print(\"values:\", events.loc[idx])\n",
    "            exit()\n",
    "    return events.loc[events.VALUE.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_events_to_timeseries(events, variable_column='VARIABLE', variables=[]):\n",
    "    metadata = events[['CHARTTIME']].sort_values(by=['CHARTTIME'])\\\n",
    "                    .drop_duplicates(keep='first').set_index('CHARTTIME')\n",
    "    timeseries = events[['CHARTTIME', variable_column, 'VALUE']]\\\n",
    "                    .sort_values(by=['CHARTTIME', variable_column, 'VALUE'], axis=0)\\\n",
    "                    .drop_duplicates(subset=['CHARTTIME', variable_column], keep='last')\n",
    "    timeseries = timeseries.pivot(index='CHARTTIME', columns=variable_column, values='VALUE').merge(metadata, left_index=True, right_index=True)\\\n",
    "                    .sort_index(axis=0).reset_index()\n",
    "    for v in variables:\n",
    "        if v not in timeseries:\n",
    "            timeseries[v] = np.nan\n",
    "    return timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_hours_elpased_to_events(events, dt, remove_charttime=True):\n",
    "    events['HOURS'] = (events.CHARTTIME - dt).apply(lambda s: s / np.timedelta64(1, 's')) / 60./60\n",
    "    if remove_charttime:\n",
    "        del events['CHARTTIME']\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef read_events(icu_stay_path, remove_null=True):\\n    events = pd.read_csv(os.path.join(icu_stay_path, \\'events.csv\\'), index_col=None)\\n    if remove_null:\\n        events = events.loc [events.VALUE.notnull()]\\n    events.CHARTTIME = pd.to_datetime(events.CHARTTIME)\\n    events.HADM_ID = events.HADM_ID.fillna(value=-1).astype(int)\\n    events.ICUSTAY_ID = events.ICUSTAY_ID.fillna(value=-1).astype(int)\\n    events.VALUEUOM = events.VALUEUOM.fillna(\\'\\').astype(str)\\n#    events.sort_values(by=[\\'CHARTTIME\\', \\'ITEMID\\', \\'ICUSTAY_ID\\'], inplace=True)\\n    return events\\n\\nnb_rows = len(stays.icustay_id.unique())\\n\\nbuggy_ids=[];\\n\\nfor ctr,icu_stay_id in enumerate(stays.icustay_id.unique()):\\n    sys.stdout.write(\\'\\rprocessing {0} of {1} ICUSTAY_IDs...\\'.format(ctr, nb_rows))\\n#for icu_stay_id in [236962]:\\n    icu_stay_dir = str(icu_stay_id)\\n    dn = os.path.join(icu_stays_root_path, icu_stay_dir)\\n    try:\\n        #icu_stay_id = int(icu_stay_dir)\\n        if not os.path.isdir(dn):\\n            raise Exception\\n    except:\\n        continue\\n    #print(\\'ICUSTAY_ID {}: \\'.format(icu_stay_id))\\n    \\n    #sys.stdout.write(\\'Subject {}: \\'.format(icu_stay_id))\\n    #sys.stdout.flush()\\n    \\n    try:\\n        icustays = pd.read_csv(os.path.join(dn, \\'stays.csv\\'))\\n        icuevents = read_events(dn)\\n    except:\\n        #print(\\'For \\'+icu_stay_dir+\\' error reading from disk!\\n\\')\\n        buggy_ids.append(icu_stay_id)\\n        continue\\n    #else:\\n        #print(\\'got {0} stays, {1} events...\\'.format(icustays.shape[0], icuevents.shape[0]))\\n    icustays.gender = transform_gender(icustays.gender)\\n    icuevents =  icuevents.merge(var_map, left_on=\\'ITEMID\\', right_index=True)\\n    if len(icuevents)==0:\\n        buggy_ids.append(icu_stay_id)\\n        continue\\n    icuevents = clean_events(icuevents)\\n    timeseries = convert_events_to_timeseries(icuevents, variables=variables)\\n    \\n    episode = add_hours_elpased_to_events(timeseries, timeseries.CHARTTIME[0]).set_index(\\'HOURS\\').sort_index(axis=0)\\n    columns = list(episode.columns)\\n    columns_sorted = sorted(columns, key=(lambda x: \"\" if x == \"Hours\" else x))\\n    episode = episode[columns_sorted]\\n    \\n    episode.to_csv(os.path.join(dn, \\'episode_timeseries.csv\\'), index_label=\\'Hours\\')\\n    \\n    \\n    '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "'''\n",
    "def read_events(icu_stay_path, remove_null=True):\n",
    "    events = pd.read_csv(os.path.join(icu_stay_path, 'events.csv'), index_col=None)\n",
    "    if remove_null:\n",
    "        events = events.loc [events.VALUE.notnull()]\n",
    "    events.CHARTTIME = pd.to_datetime(events.CHARTTIME)\n",
    "    events.HADM_ID = events.HADM_ID.fillna(value=-1).astype(int)\n",
    "    events.ICUSTAY_ID = events.ICUSTAY_ID.fillna(value=-1).astype(int)\n",
    "    events.VALUEUOM = events.VALUEUOM.fillna('').astype(str)\n",
    "#    events.sort_values(by=['CHARTTIME', 'ITEMID', 'ICUSTAY_ID'], inplace=True)\n",
    "    return events\n",
    "\n",
    "nb_rows = len(stays.icustay_id.unique())\n",
    "\n",
    "buggy_ids=[];\n",
    "\n",
    "for ctr,icu_stay_id in enumerate(stays.icustay_id.unique()):\n",
    "    sys.stdout.write('\\rprocessing {0} of {1} ICUSTAY_IDs...'.format(ctr, nb_rows))\n",
    "#for icu_stay_id in [236962]:\n",
    "    icu_stay_dir = str(icu_stay_id)\n",
    "    dn = os.path.join(icu_stays_root_path, icu_stay_dir)\n",
    "    try:\n",
    "        #icu_stay_id = int(icu_stay_dir)\n",
    "        if not os.path.isdir(dn):\n",
    "            raise Exception\n",
    "    except:\n",
    "        continue\n",
    "    #print('ICUSTAY_ID {}: '.format(icu_stay_id))\n",
    "    \n",
    "    #sys.stdout.write('Subject {}: '.format(icu_stay_id))\n",
    "    #sys.stdout.flush()\n",
    "    \n",
    "    try:\n",
    "        icustays = pd.read_csv(os.path.join(dn, 'stays.csv'))\n",
    "        icuevents = read_events(dn)\n",
    "    except:\n",
    "        #print('For '+icu_stay_dir+' error reading from disk!\\n')\n",
    "        buggy_ids.append(icu_stay_id)\n",
    "        continue\n",
    "    #else:\n",
    "        #print('got {0} stays, {1} events...'.format(icustays.shape[0], icuevents.shape[0]))\n",
    "    icustays.gender = transform_gender(icustays.gender)\n",
    "    icuevents =  icuevents.merge(var_map, left_on='ITEMID', right_index=True)\n",
    "    if len(icuevents)==0:\n",
    "        buggy_ids.append(icu_stay_id)\n",
    "        continue\n",
    "    icuevents = clean_events(icuevents)\n",
    "    timeseries = convert_events_to_timeseries(icuevents, variables=variables)\n",
    "    \n",
    "    episode = add_hours_elpased_to_events(timeseries, timeseries.CHARTTIME[0]).set_index('HOURS').sort_index(axis=0)\n",
    "    columns = list(episode.columns)\n",
    "    columns_sorted = sorted(columns, key=(lambda x: \"\" if x == \"Hours\" else x))\n",
    "    episode = episode[columns_sorted]\n",
    "    \n",
    "    episode.to_csv(os.path.join(dn, 'episode_timeseries.csv'), index_label='Hours')\n",
    "    \n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.Series(buggy_ids).to_csv('../data/buggy_ids.csv', index=False)\n",
    "#working = list(set(stays.icustay_id.unique())- set(buggy_ids) )\n",
    "#pd.Series(working).to_csv('../data/working_ids.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
